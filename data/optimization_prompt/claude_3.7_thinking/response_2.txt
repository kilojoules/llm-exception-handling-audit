# HDF5 File Merge Error Analysis and Solution

## Issue Diagnosis

The error occurs during the final stage of the wind farm layout optimization process when the main script attempts to merge multiple worker HDF5 files. Specifically, it fails with:

```
OSError: Unable to synchronously open file (file signature not found)
```

Looking at the evidence:

1. The optimization completed 2999/3000 jobs successfully
2. The error occurs during the merging phase with `h5py.File(worker_file, 'r')`
3. The listing of the temp directory reveals a **0-byte worker file**: `0 -rw-rw-r-- 1 juqu juqu 0 Feb 25 11:09 worker_61817.h5`

This is the root cause: when a worker process fails to write any data to its HDF5 file (likely due to a crash or termination), it leaves an empty file with no HDF5 header signature. The merging code currently doesn't handle this situation and crashes when it encounters this invalid file.

## Solution

The code needs to be modified to safely handle invalid or corrupted worker files. Here's how to improve the file merging section in the `main()` function:

```
def main():
    """Main function to run the optimization"""
    # ... existing code ...

    # Merge worker files into final output
    if not args.no_hot_start and os.path.exists(args.output):
        # Use append mode to preserve existing results
        mode = 'a'
    else:
        # Use write mode for new file or when hot start is disabled
        mode = 'w'
    
    successful_merges = 0
    failed_merges = 0
    
    with h5py.File(args.output, mode) as h5_out:
        # Add metadata
        h5_out.attrs['grid_size'] = args.grid_size
        h5_out.attrs['random_pct'] = args.random_pct
        h5_out.attrs['total_configs'] = len(configs) + len(completed_configs)
        h5_out.attrs['successful_configs'] = success_count + len(completed_configs)
        
        # Copy data from worker files with error handling
        for worker_file in glob.glob(os.path.join(temp_dir, "worker_*.h5")):
            # First check if file is valid (non-empty and readable)
            if os.path.getsize(worker_file) == 0:
                logger.warning(f"Skipping empty worker file: {worker_file}")
                failed_merges += 1
                # Remove the empty file
                try:
                    os.remove(worker_file)
                except OSError as e:
                    logger.error(f"Failed to remove empty file {worker_file}: {e}")
                continue
                
            try:
                with h5py.File(worker_file, 'r') as h5_in:
                    # Check if file has any valid data besides 'init'
                    has_valid_data = False
                    for key in h5_in:
                        if key != 'init':
                            has_valid_data = True
                            if key not in h5_out:  # Avoid duplicates
                                h5_out.copy(h5_in[key], key)
                                successful_merges += 1
                    
                    if not has_valid_data:
                        logger.warning(f"Worker file has no valid data: {worker_file}")
                        failed_merges += 1
                
                # Clean up worker file only if successfully processed
                os.remove(worker_file)
                
            except (OSError, IOError, RuntimeError) as e:
                # Handle corrupted HDF5 files
                logger.error(f"Failed to open worker file {worker_file}: {e}")
                failed_merges += 1
                
                # Rename the problematic file instead of removing it
                # This allows for later investigation if needed
                error_file = f"{worker_file}.error"
                try:
                    os.rename(worker_file, error_file)
                    logger.info(f"Renamed corrupt file to: {error_file}")
                except OSError as rename_err:
                    logger.error(f"Failed to rename corrupt file {worker_file}: {rename_err}")
    
    # Log merge statistics
    logger.info(f"Merged {successful_merges} datasets from worker files")
    if failed_merges > 0:
        logger.warning(f"Failed to merge {failed_merges} worker files")
    
    # Try to clean up temp directory, but don't fail if there are still files
    try:
        remaining_files = glob.glob(os.path.join(temp_dir, "*"))
        if not remaining_files:
            os.rmdir(temp_dir)
            logger.info(f"Removed temporary directory: {temp_dir}")
        else:
            logger.warning(f"Temporary directory not removed, contains {len(remaining_files)} files: {temp_dir}")
    except OSError as e:
        logger.error(f"Failed to remove temporary directory {temp_dir}: {e}")
    
    logger.info(f"Results saved to {args.output}")
```


## Additional Improvements to Consider

To make the worker process more robust, we should also modify the worker initialization to better handle failures:


```
def worker_init(output_dir):
    """Initialize per-worker temporary HDF5 file"""
    import os
    import logging
    import h5py
    import numpy as np
    from multiprocessing import current_process
    
    logger = logging.getLogger(__name__)
    worker_id = current_process().pid
    worker_file = os.path.join(output_dir, f"worker_{worker_id}.h5")
    
    # Store file path on worker process object
    current_process().worker_file = worker_file
    
    # Initialize empty HDF5 file with a test dataset to ensure it's valid
    max_retries = 3
    for attempt in range(max_retries):
        try:
            with h5py.File(worker_file, 'w') as f:
                f.create_dataset('init', data=np.array([1]))
                # Add worker metadata
                f.attrs['worker_id'] = worker_id
                f.attrs['start_time'] = time.time()
                logger.info(f"Worker {worker_id}: Successfully initialized HDF5 file (attempt {attempt+1})")
                break
        except Exception as e:
            logger.error(f"Worker {worker_id}: Failed to create HDF5 file (attempt {attempt+1}): {str(e)}")
            if attempt < max_retries - 1:
                # Remove possibly corrupted file before retry
                try:
                    if os.path.exists(worker_file):
                        os.remove(worker_file)
                    time.sleep(1)  # Wait a bit before retrying
                except Exception as remove_err:
                    logger.error(f"Worker {worker_id}: Failed to remove corrupted file: {str(remove_err)}")
            else:
                logger.critical(f"Worker {worker_id}: Failed to initialize after {max_retries} attempts!")
                # Create a marker file to indicate this worker failed initialization
                with open(f"{worker_file}.failed", 'w') as marker:
                    marker.write(f"Worker {worker_id} failed to initialize: {str(e)}")

    # Force process affinity to separate cores (Linux only)
    try:
        import psutil
        process = psutil.Process()
        # Get worker index from Pool (not the pid)
        worker_idx = int(current_process().name.split('-')[-1]) if '-' in current_process().name else 0
        # Set affinity to a specific CPU core
        process.cpu_affinity([worker_idx % os.cpu_count()])
        logger.info(f"Worker {worker_id} assigned to CPU {worker_idx % os.cpu_count()}")
    except Exception as e:
        logger.warning(f"Worker {worker_id}: CPU affinity setup failed: {str(e)}")
```

## Enhanced Layout Optimization Function

We should also improve the `optimize_layout` function to handle failures better and ensure it always properly closes the HDF5 file:

```
def optimize_layout(config, farm_boundaries, grid_size=18, random_pct=30, update_interval=None):
    """Run optimization and save to worker-specific temp file
    
    Args:
        config: Configuration dictionary with farm_idx, type_idx, etc.
        farm_boundaries: List of farm boundary coordinates
        grid_size: Number of grid points in each dimension for smart start
        random_pct: Percentage of random positions to use in smart start
    """
    h5_file = None
    try:
        worker_file = current_process().worker_file
        farm_idx = config['farm_idx']
        boundary = np.array(farm_boundaries[farm_idx]).T.tolist()
        
        # Get turbine type
        turbine_types = get_turbine_types()
        turbine = turbine_types[config['type_idx']]

        # Initialize site - try to load from cache first
        site_cache_file = f"site_cache_farm_{farm_idx}.nc"
        if os.path.exists(site_cache_file):
            try:
                site = XRSite.load(site_cache_file)
                logger.info(f"Loaded site from cache: {site_cache_file}")
            except Exception as e:
                logger.warning(f"Failed to load site from cache: {e}")
                site = UniformSite(ti=0.1)
        else:
            site = UniformSite(ti=0.1)
        
        # Initialize random layout positions
        x_min, x_max = min(b[0] for b in boundary), max(b[0] for b in boundary)
        y_min, y_max = min(b[1] for b in boundary), max(b[1] for b in boundary)
        x = np.random.uniform(x_min, x_max, config['n_turbines'])
        y = np.random.uniform(y_min, y_max, config['n_turbines'])

        # Create optimization problem
        problem = TopFarmProblem(
            design_vars={'x': x, 'y': y},
            cost_comp=PyWakeAEPCostModelComponent(
                Nygaard_2022(site, turbine), 
                n_wt=config['n_turbines'],
                grad_method=autograd),
            constraints=[
                XYBoundaryConstraint(boundary, boundary_type='polygon'),
                SpacingConstraint(config['diameter'] * 1.1)  # 1.1D spacing constraint
            ]
        )

        # Run optimization with smart start
        xs = np.linspace(x_min, x_max, grid_size)
        ys = np.linspace(y_min, y_max, grid_size)
        problem.smart_start(*np.meshgrid(xs, ys), 
                          problem.cost_comp.get_aep4smart_start(),
                          random_pct=random_pct,
                          seed=config['ss_seed'],
                          show_progress=False)
        
        # Verify results before saving (basic sanity check)
        if problem['x'] is None or problem['y'] is None or len(problem['x']) != config['n_turbines']:
            logger.error(f"Invalid optimization results for farm {farm_idx}, type {config['type_idx']}, seed {config['ss_seed']}")
            return False

        # Open HDF5 file for writing
        h5_file = h5py.File(worker_file, 'a')
        
        # Generate a unique group name and create it
        group_name = f"farm{farm_idx}_t{config['type_idx']}_s{config['ss_seed']}"
        grp = h5_file.create_group(group_name)
        
        # Save layout and AEP data
        grp.create_dataset('layout', data=np.vstack([problem['x'], problem['y']]))
        grp.create_dataset('aep', data=problem.cost) 
        
        # Save configuration metadata
        for k, v in config.items():
            grp.attrs[k] = v
            
        # Add timestamp for traceability
        grp.attrs['timestamp'] = time.time()
        
        # Flush data to disk
        h5_file.flush()
        
        logger.info(f"Successfully optimized farm {farm_idx}, type {config['type_idx']}, seed {config['ss_seed']}")
        return True

    except Exception as e:
        # Log the full traceback for better debugging
        import traceback
        logger.error(f"Failed optimization for farm {config.get('farm_idx', 'unknown')}, "
                     f"type {config.get('type_idx', 'unknown')}, seed {config.get('ss_seed', 'unknown')}")
        logger.error(f"Error details: {str(e)}")
        logger.error(f"Traceback: {traceback.format_exc()}")
        return False
    
    finally:
        # Ensure the file is properly closed
        if h5_file is not None and h5_file.id.valid:
            try:
                h5_file.close()
            except Exception as close_err:
                logger.error(f"Error closing HDF5 file: {str(close_err)}")
        
        # Clean up memory
        gc.collect()
```

## Progress Monitoring Enhancements

Finally, since the issue reveals the script was running for 9+ hours and only detected the problem at the end, we should add progressive file validation:

```
def validate_worker_files(temp_dir, check_interval=60):
    """Periodically validate worker files in a background thread
    
    Args:
        temp_dir: Directory containing worker files
        check_interval: Time in seconds between checks
    """
    import threading
    import time
    import os
    import glob
    import logging
    
    logger = logging.getLogger(__name__)
    
    def monitor_thread():
        last_check = 0
        while True:
            try:
                # Sleep for the check interval
                time.sleep(check_interval)
                
                # Check if we should stop
                if hasattr(monitor_thread, 'stop_flag') and monitor_thread.stop_flag:
                    logger.info("Worker file monitor stopping")
                    break
                
                current_time = time.time()
                if current_time - last_check < check_interval:
                    continue
                    
                last_check = current_time
                
                # Find all worker files
                worker_files = glob.glob(os.path.join(temp_dir, "worker_*.h5"))
                if not worker_files:
                    continue
                    
                invalid_files = []
                
                # Check each file
                for worker_file in worker_files:
                    # Skip files that are currently being written (based on modified time)
                    if current_time - os.path.getmtime(worker_file) < 10:  # Skip files modified in last 10 seconds
                        continue
                        
                    # Check if file is empty
                    if os.path.getsize(worker_file) == 0:
                        invalid_files.append((worker_file, "Empty file"))
                        continue
                        
                    # Try to open the file to validate HDF5 structure
                    try:
                        with h5py.File(worker_file, 'r') as f:
                            # Basic validation - file opens and has expected structure
                            pass
                    except Exception as e:
                        invalid_files.append((worker_file, f"Invalid HDF5: {str(e)}"))
                
                # Report any invalid files
                if invalid_files:
                    logger.warning(f"Found {len(invalid_files)} invalid worker files during periodic check")
                    for file_path, reason in invalid_files:
                        logger.warning(f"  - {file_path}: {reason}")
                        
                        # Mark file as invalid
                        try:
                            os.rename(file_path, f"{file_path}.invalid")
                            logger.info(f"Renamed invalid file to: {file_path}.invalid")
                        except OSError as rename_err:
                            logger.error(f"Failed to rename invalid file {file_path}: {rename_err}")
                
            except Exception as e:
                logger.error(f"Error in worker file monitor: {str(e)}")
    
    # Start monitoring thread
    monitor_thread.stop_flag = False
    thread = threading.Thread(target=monitor_thread, daemon=True)
    thread.start()
    
    # Return thread so it can be stopped later
    return thread

# Add to main function before creating the Pool:
monitor_thread = validate_worker_files(temp_dir)

# Add to the end of main function:
if 'monitor_thread' in locals():
    monitor_thread.stop_flag = True
    # No need to join as it's a daemon thread
```

## Implementation Summary

The issue was caused by an invalid (empty) HDF5 worker file that was created during the optimization process but never populated with data. When the main process tried to merge all worker files at the end, it encountered this invalid file and crashed.

The key improvements I've recommended:

1. **Robust File Merging**: 
   - Check file size before attempting to open
   - Properly handle corrupted/invalid HDF5 files with try/except
   - Keep track of successful and failed merges
   - Preserve problematic files for investigation

2. **Improved Worker Initialization**:
   - Implement retry logic for file creation
   - Better error handling and reporting
   - Create marker files for failed initializations

3. **Enhanced Optimization Function**:
   - Proper resource cleanup in finally blocks
   - Result validation before saving
   - Better error handling with detailed logs
   - Explicit file flushing and closing

4. **Background File Validation**:
   - Periodically check worker files for validity
   - Identify and mark problematic files early
   - Prevent the script from running for hours only to fail at the end

These changes will make the script much more resilient to failures and provide better diagnostics when issues occur, allowing you to successfully process all configurations even if some worker processes fail.
