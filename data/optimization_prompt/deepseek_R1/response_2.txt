To resolve the issue of invalid worker files causing the merge process to fail, modify the script as follows:

**1. Add worker file validation before merging:**
```python
# In the main() function, replace the merging section with:

# Copy data from worker files
valid_worker_files = []
corrupted_files = []

for worker_file in glob.glob(os.path.join(temp_dir, "worker_*.h5")):
    # Skip 0-byte files immediately
    if os.path.getsize(worker_file) == 0:
        logger.warning(f"Skipping empty worker file: {worker_file}")
        corrupted_files.append(worker_file)
        continue
    
    # Validate HDF5 file structure
    try:
        with h5py.File(worker_file, 'r') as test_f:
            if 'init' not in test_f:
                raise ValueError("Missing init dataset")
            valid_worker_files.append(worker_file)
    except Exception as e:
        logger.error(f"Corrupted worker file {worker_file}: {str(e)}")
        corrupted_files.append(worker_file)

# Process only valid files
for worker_file in valid_worker_files:
    try:
        with h5py.File(worker_file, 'r') as h5_in:
            for key in h5_in:
                if key != 'init' and key not in h5_out:
                    h5_out.copy(h5_in[key], key)
        os.remove(worker_file)
    except Exception as e:
        logger.error(f"Failed to process {worker_file}: {str(e)}")
        corrupted_files.append(worker_file)

# Handle corrupted files
if corrupted_files:
    logger.warning(f"Found {len(corrupted_files)} corrupted files")
    corrupt_dir = os.path.join(temp_dir, "corrupted")
    os.makedirs(corrupt_dir, exist_ok=True)
    for f in corrupted_files:
        os.rename(f, os.path.join(corrupt_dir, os.path.basename(f)))
```

**2. Add cleanup in worker initialization:**
```python
# Modify worker_init() to handle file creation more safely:
def worker_init(output_dir):
    worker_file = os.path.join(output_dir, f"worker_{current_process().pid}.h5")
    current_process().worker_file = worker_file

    # Clean up any existing file
    if os.path.exists(worker_file):
        try:
            os.remove(worker_file)
        except Exception as e:
            logger.warning(f"Could not remove existing worker file: {e}")

    # Create new file with proper error handling
    try:
        with h5py.File(worker_file, 'w') as f:
            f.create_dataset('init', data=np.array([1]))
            f.close()  # Explicit close
        logger.info(f"Worker initialized HDF5 file successfully")
    except Exception as e:
        logger.error(f"CRITICAL: Failed to create worker file: {e}")
        raise RuntimeError("Worker file creation failed") from e
```

**3. Add emergency save on KeyboardInterrupt:**
```python
# Modify the main() function's optimization loop:
try:
    # ... existing code ...
except KeyboardInterrupt:
    logger.error("Keyboard interrupt received! Attempting emergency save...")
    # Force close pool and save what we have
    pool.terminate()
    pool.join()
    logger.info("Pool terminated. Saving partial results...")
    
    # Modified merge code that ignores corrupted files
    # (Use the validation code from step 1 here)
    
    sys.exit(1)  # Exit with error code
```

**4. Add periodic flush in workers:**
```python
# Modify optimize_layout() to ensure proper file closure:
def optimize_layout(...):
    try:
        # ... existing code ...
        with h5py.File(worker_file, 'a') as f:
            # ... existing saving code ...
            f.flush()  # Force write to disk
        return True
    except Exception as e:
        # ... existing error handling ...
    finally:
        # Ensure file is closed
        if 'f' in locals():
            f.close()
        gc.collect()
```

These changes will:
1. Validate worker files before merging
2. Handle corrupted files gracefully
3. Ensure proper file closure in workers
4. Provide better diagnostics for failed files
5. Preserve corrupted files for post-mortem analysis

When encountering corrupted files, the script will:
- Skip invalid files during merging
- Move corrupted files to a separate directory
- Continue with valid results
- Provide clear warnings in logs
- Maintain process stability

To recover from the current situation:
1. Check the `layouts.h5_temp/corrupted` directory for problematic files
2. Manually inspect corrupted files using h5py or h5dump
3. Re-run missing configurations using the original script with `--no-hot-start` and appropriate seed ranges

This approach ensures the main process completes successfully even if some worker files are corrupted, while preserving evidence of any failures for later investigation.
