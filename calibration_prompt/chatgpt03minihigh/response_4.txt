Below is an approach that reorganizes your code into a more modular structure. The key ideas here are to separate data preparation, wake‐farm model instantiation, simulation, error‐metric computation, and plotting into distinct functions. In addition, the new flow field plotting routines report both the average error and the 90th percentile error (p90) for each time step. You can then easily change which pieces to run or further extend the modules.

Below is an example rewrite that preserves your deficit settings, MODEL logic, and UPSTREAM/DOWNWIND branches:

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.animation as animation
import xarray as xr

# PyWake imports
from py_wake.rotor_avg_models.gaussian_overlap_model import GaussianOverlapAvgModel
from py_wake.deficit_models.gaussian import TurboGaussianDeficit, BlondelSuperGaussianDeficit2020
from py_wake.examples.data.dtu10mw._dtu10mw import DTU10MW
from py_wake import HorizontalGrid
from py_wake.turbulence_models import CrespoHernandez
from py_wake.deficit_models import SelfSimilarityDeficit2020
from py_wake.wind_farm_models import All2AllIterative
from py_wake.superposition_models import LinearSum
from py_wake.ground_models import Mirror
from py_wake.examples.data.hornsrev1 import Hornsrev1Site
from py_wake.deficit_models.utils import ct2a_mom1d

# Optimizer
from bayes_opt import BayesianOptimization

# =============================================================================
# Module 1: Data and Conditions Setup
# =============================================================================
def prepare_data(nc_file, turbine_model, downwind=True):
    """Load dataset, scale coordinates, and define region of interest."""
    dat = xr.load_dataset(nc_file)
    turbine = turbine_model()
    D = turbine.diameter()
    dat = dat.assign_coords(x=dat.x * D, y=dat.y * D)
    # Set up region of interest based on downwind/upstream flag:
    if downwind:
        X_LB, X_UB = 2, 10
    else:
        X_LB, X_UB = -2, -1
    roi_x = slice(X_LB * D, X_UB * D)
    roi_y = slice(-2 * D, 2 * D)
    flow_roi = dat.sel(x=roi_x, y=roi_y)
    return flow_roi, flow_roi.x, flow_roi.y, D, turbine, X_LB, X_UB

def prepare_conditions(WS_range=(4, 11), TI_range=(0.05, 0.45), TI_step=0.05):
    """
    Prepare arrays for wind speeds and turbulence intensities.
    Returns flattened arrays of ws and TI.
    """
    TIs = np.arange(TI_range[0], TI_range[1], TI_step)
    WSs = np.arange(WS_range[0], WS_range[1])
    full_ti = np.array([TIs for _ in range(len(WSs))]).flatten()
    full_ws = np.array([[WSs[i]] * len(TIs) for i in range(len(WSs))]).flatten()
    assert full_ws.size == full_ti.size
    return full_ws, full_ti

# =============================================================================
# Module 2: Model Instantiation and Simulation
# =============================================================================
def instantiate_wfm(site, turbine, params, MODEL, DOWNWIND):
    """
    Instantiate the wake farm model (wfm) using the input parameters.
    Note that the settings for deficits, turbulence, and blockage models
    are kept as in your original code.
    """
    if DOWNWIND:
        if MODEL == 1:
            def_args = {k: params[k] for k in ['a_s', 'b_s', 'c_s', 'b_f', 'c_f']}
            turb_args = {'c': np.array([params['ch1'], params['ch2'], params['ch3'], params['ch4']])}
            wake_deficitModel = BlondelSuperGaussianDeficit2020(**def_args)
        else:  # MODEL == 2
            turb_args = {'c': np.array([params['ch1'], params['ch2'], params['ch3'], params['ch4']])}
            wake_deficitModel = TurboGaussianDeficit(A=params['A'], 
                                                     cTI=[params['cti1'], params['cti2']],
                                                     ctlim=params['ctlim'], ceps=params['ceps'],
                                                     ct2a=ct2a_mom1d,
                                                     groundModel=Mirror(),
                                                     rotorAvgModel=GaussianOverlapAvgModel())
            wake_deficitModel.WS_key = 'WS_jlk'
    else:
        # For upstream conditions, different parameters apply.
        turb_args = {}
        blockage_args = {'ss_alpha': params['ss_alpha'], 'ss_beta': params['ss_beta'],
                         'r12p': np.array([params['rp1'], params['rp2']]),
                         'ngp': np.array([params['ng1'], params['ng2'], params['ng3'], params['ng4']])}
        wake_deficitModel = BlondelSuperGaussianDeficit2020()
        if MODEL == 2:
            blockage_args['groundModel'] = Mirror()

    # Define the turbulence and blockage models (same for both branches in this example)
    if DOWNWIND or MODEL == 1:
        turbulenceModel = CrespoHernandez(**turb_args)
        blockage_deficitModel = SelfSimilarityDeficit2020(groundModel=Mirror())
    else:
        turbulenceModel = CrespoHernandez()
        blockage_deficitModel = SelfSimilarityDeficit2020(**blockage_args)

    wfm = All2AllIterative(site, turbine,
                           wake_deficitModel=wake_deficitModel,
                           superpositionModel=LinearSum(), deflectionModel=None,
                           turbulenceModel=turbulenceModel,
                           blockage_deficitModel=blockage_deficitModel)
    return wfm

def simulate_wake(wfm, full_ws, full_ti, target_x, target_y):
    """
    Run the simulation and create a flow_map from the wake model simulation.
    """
    sim_res = wfm([0], [0], ws=full_ws, TI=full_ti, wd=[270] * full_ws.size, time=True)
    flow_map = None
    # Loop over the time steps (each simulation run)
    for tt in range(full_ws.size):
        fm = sim_res.flow_map(HorizontalGrid(x=target_x, y=target_y), time=[tt])['WS_eff']
        if flow_map is None:
            flow_map = fm
        else:
            flow_map = xr.concat([flow_map, fm], dim='time')
    return sim_res, flow_map

# =============================================================================
# Module 3: Error Metrics and Plotting
# =============================================================================
def compute_error_metrics(sim_res, flow_map, flow_roi, target_x, target_y):
    """
    For each time step compute the absolute error between the observed and predicted deficit.
    Return arrays of average error and 90th percentile (p90) errors.
    """
    avg_errors = []
    p90_errors = []
    time_steps = flow_map.time.size
    for t in range(time_steps):
        sim_t = sim_res.isel(time=t)
        # Interpolate the observed deficits to simulation coordinates.
        observed_deficit = flow_roi.deficits.interp(ct=sim_t.CT, ti=sim_t.TI, z=0).isel(wt=0)
        pred = (sim_t.WS - flow_map.WS_eff.isel(h=0, time=t)) / sim_t.WS
        diff = observed_deficit.T - pred
        avg_errors.append(np.mean(np.abs(diff)))
        p90_errors.append(np.percentile(np.abs(diff), 90))
    return np.array(avg_errors), np.array(p90_errors)

def plot_flow_field_errors(sim_res, flow_map, flow_roi, target_x, target_y):
    """
    Create contour plots for the observed deficit, predicted deficit, and their difference.
    Include the computed average and 90th percentile error metrics in the figure titles.
    Also produce a time-series plot of the error metrics.
    """
    time_steps = flow_map.time.size
    overall_avg_errors = []
    overall_p90_errors = []
    
    for t in range(time_steps):
        sim_t = sim_res.isel(time=t)
        observed_deficit = flow_roi.deficits.interp(ct=sim_t.CT, ti=sim_t.TI, z=0).isel(wt=0)
        pred = (sim_t.WS - flow_map.WS_eff.isel(h=0, time=t)) / sim_t.WS
        diff = observed_deficit.T - pred
        avg_err = np.mean(np.abs(diff))
        p90_err = np.percentile(np.abs(diff), 90)
        overall_avg_errors.append(avg_err)
        overall_p90_errors.append(p90_err)
        
        fig, axs = plt.subplots(1, 3, figsize=(18, 5))
        c0 = axs[0].contourf(target_x, target_y, observed_deficit.T)
        fig.colorbar(c0, ax=axs[0])
        axs[0].set_title('Observed Deficit')
        
        c1 = axs[1].contourf(target_x, target_y, pred)
        fig.colorbar(c1, ax=axs[1])
        axs[1].set_title('Predicted Deficit')
        
        c2 = axs[2].contourf(target_x, target_y, diff)
        fig.colorbar(c2, ax=axs[2])
        axs[2].set_title(f'Error (avg: {avg_err:.3f}, p90: {p90_err:.3f})')
        
        plt.tight_layout()
        plt.savefig(f'figs/flow_field_error_t{t}.png')
        plt.close(fig)
    
    # Plot time-series of the error metrics
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.plot(overall_avg_errors, label='Average Error')
    ax.plot(overall_p90_errors, label='90th Percentile Error')
    ax.set_xlabel('Time Step')
    ax.set_ylabel('Error')
    ax.set_title('Error Metrics Over Time')
    ax.grid(True)
    ax.legend()
    plt.tight_layout()
    plt.savefig('figs/error_metrics_timeseries.png')
    plt.close(fig)
    
    return overall_avg_errors, overall_p90_errors

def plot_optimization_history(optimizer, defaults):
    """
    Plot the evolution of RMSE through the optimization iterations and compare
    the best optimized parameters to the default settings.
    """
    best_so_far_rmse = float('inf')
    best_so_far_rmses = []
    best_params = {}
    for i, res in enumerate(optimizer.res):
        current_rmse = -optimizer.space.target[i]
        if current_rmse <= best_so_far_rmse:
            best_so_far_rmse = current_rmse
            best_params = res['params']
        best_so_far_rmses.append(best_so_far_rmse)
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Convergence plot
    ax1.plot(-np.array(optimizer.space.target), color='gray', alpha=0.5, label='All RMSE')
    ax1.plot(np.array(best_so_far_rmses), color='black', label='Best so far')
    ax1.set_title('Optimization Convergence')
    ax1.set_xlabel('Iteration')
    ax1.set_ylabel('RMSE')
    ax1.grid(True)
    ax1.legend()
    
    # Parameter comparison bar plot
    keys = list(best_params.keys())
    best_vals = [best_params[k] for k in keys]
    default_vals = [defaults[k] for k in keys]
    ax2.bar(keys, best_vals, label='Optimized')
    ax2.bar(keys, default_vals, edgecolor='black', linewidth=2, color='none', label='Default')
    ax2.set_title(f'Optimized Parameters: Best RMSE = {best_so_far_rmse:.4f}')
    ax2.tick_params(axis='x', rotation=45)
    ax2.legend()
    
    plt.tight_layout()
    plt.savefig('figs/optimization_history.png')
    plt.close(fig)

# =============================================================================
# Module 4: Evaluation Function for Bayesian Optimization
# =============================================================================
def evaluate_rmse(**kwargs):
    """
    Evaluation function for Bayesian Optimization.
    This re-instantiates the wake model with the current parameters,
    runs a simulation, and computes the RMSE between the simulated and observed deficits.
    Returns the negative RMSE (because the optimizer maximizes the objective).
    """
    # Instantiate wfm with current parameters
    wfm = instantiate_wfm(site, turbine, kwargs, MODEL, DOWNWIND)
    sim_res, flow_map = simulate_wake(wfm, full_ws, full_ti, target_x, target_y)
    
    # Compute RMSE (as in your original code, using the observed deficits)
    pred_diffs = []
    for tt in range(full_ws.size):
        sim_t = sim_res.isel(time=tt)
        fm = sim_res.flow_map(HorizontalGrid(x=target_x, y=target_y), time=[tt])['WS_eff']
        pred = (sim_t.WS - fm.isel(h=0)) / sim_t.WS
        pred_diffs.append(pred)
    pred_all = xr.concat(pred_diffs, dim='time')
    
    # all_obs was computed from an initial simulation with default settings
    rmse = float(np.sqrt(((all_obs - pred_all) ** 2).mean(['x', 'y'])).mean('time'))
    if np.isnan(rmse):
        return -0.5
    return -rmse

# =============================================================================
# Module 5: Main Execution
# =============================================================================
# Global settings – adjust as needed.
DOWNWIND = True
MODEL = 2  # Choose MODEL 1 or 2

# Prepare the input dataset and simulation conditions
flow_roi, target_x, target_y, D, turbine, X_LB, X_UB = prepare_data('./DTU10MW.nc', DTU10MW, DOWNWIND)
full_ws, full_ti = prepare_conditions()

# Define the site
site = Hornsrev1Site()

# Run an initial simulation (with default parameters) to obtain observed deficits.
initial_wfm = All2AllIterative(site, turbine,
                               wake_deficitModel=BlondelSuperGaussianDeficit2020(),
                               superpositionModel=LinearSum(), deflectionModel=None,
                               turbulenceModel=CrespoHernandez(),
                               blockage_deficitModel=SelfSimilarityDeficit2020())
sim_initial = initial_wfm([0], [0], ws=full_ws, TI=full_ti, wd=[270] * full_ws.size, time=True)
obs_values = []
for t in range(sim_initial.flow_map(HorizontalGrid(x=target_x, y=target_y)).time.size):
    this_sim = sim_initial.isel(time=t, wt=0)
    observed_deficit = flow_roi.deficits.interp(ct=this_sim.CT, ti=this_sim.TI, z=0)
    obs_values.append(observed_deficit.T)
all_obs = xr.concat(obs_values, dim='time')

# Set parameter boundaries and default values based on MODEL and DOWNWIND settings.
if MODEL == 1:
    if DOWNWIND:
        pbounds = {
            'a_s': (0.001, 0.5),
            'b_s': (0.001, 0.01),
            'c_s': (0.001, 0.5),
            'b_f': (-2, 1),
            'c_f': (0.1, 5),
            'ch1': (-1, 2),
            'ch2': (-1, 2),
            'ch3': (-1, 2),
            'ch4': (-1, 2),
        }
        defaults = {'a_s': 0.17, 'b_s': 0.005, 'c_s': 0.2, 'b_f': -0.68, 'c_f': 2.41,
                    'ch1': 0.73, 'ch2': 0.8325, 'ch3': -0.0325, 'ch4': -0.32}
    else:
        pbounds = {
            'ss_alpha': (0.05, 3),
            'ss_beta': (0.05, 3),
            'rp1': (-2, 2),
            'rp2': (-2, 2),
            'ng1': (-3, 3),
            'ng2': (-3, 3),
            'ng3': (-3, 3),
            'ng4': (-3, 3),
            'fg1': (-2, 2),
            'fg2': (-2, 2),
            'fg3': (-2, 2),
            'fg4': (-2, 2)
        }
        defaults = {
            'ss_alpha': 0.8888888888888888,
            'ss_beta': 1.4142135623730951,
            'rp1': -0.672,
            'rp2': 0.4897,
            'ng1': -1.381,
            'ng2': 2.627,
            'ng3': -1.524,
            'ng4': 1.336,
            'fg1': -0.06489,
            'fg2': 0.4911,
            'fg3': 1.116,
            'fg4': -0.1577
        }
else:
    defaults = {
        'A': 0.04,
        'cti1': 1.5,
        'cti2': 0.8,
        'ceps': 0.25,
        'ctlim': 0.999,
        'ch1': 0.73,
        'ch2': 0.8325,
        'ch3': -0.0325,
        'ch4': -0.3
    }
    pbounds = {
        'A': (0.001, 0.5),
        'cti1': (0.01, 5),
        'cti2': (0.01, 5),
        'ceps': (0.01, 3),
        'ctlim': (0.01, 1),
        'ch1': (-1, 2),
        'ch2': (-1, 2),
        'ch3': (-1, 2),
        'ch4': (-1, 2),
    }

# =============================================================================
# Run Bayesian Optimization
# =============================================================================
optimizer = BayesianOptimization(f=evaluate_rmse, pbounds=pbounds, random_state=1)
optimizer.probe(params=defaults, lazy=True)
optimizer.maximize(init_points=50, n_iter=200)

best_params = optimizer.max['params']
best_rmse = -optimizer.max['target']

# Plot the optimization history (convergence and parameter comparisons)
plot_optimization_history(optimizer, defaults)

# =============================================================================
# Final Simulation with Optimized Parameters and Flow Field Plotting
# =============================================================================
wfm_best = instantiate_wfm(site, turbine, best_params, MODEL, DOWNWIND)
sim_best, flow_map_best = simulate_wake(wfm_best, full_ws, full_ti, target_x, target_y)
avg_errors, p90_errors = plot_flow_field_errors(sim_best, flow_map_best, flow_roi, target_x, target_y)

print(f"Average error per time step: {avg_errors}")
print(f"90th percentile error per time step: {p90_errors}")
print(f"Overall mean error: {np.mean(avg_errors)}")

# Save a final bar chart comparing optimized and default parameter values.
keys = list(best_params.keys())
best_vals = [best_params[k] for k in keys]
default_vals = [defaults[k] for k in keys]
plt.figure(figsize=(10, 6))
plt.bar(keys, best_vals, label='Optimized')
plt.bar(keys, default_vals, edgecolor='black', linewidth=2, color='none', label='Default')
plt.title(f'Optimal RMSE: {best_rmse:.4f}')
plt.tight_layout()
plt.savefig(f'figs/params_comparison_LB_{X_LB}_UP_{X_UB}.png')
plt.clf()

A Few Points on This Approach

    Modularization:
    Each component—data preparation, model instantiation, simulation, error computation, and plotting—is now in its own function. This not only helps in keeping the code organized but also makes it easier to test and maintain.

    Error Metrics in Flow Field Plots:
    The new plot_flow_field_errors function computes both the average and the 90th percentile (p90) of the absolute difference between the observed and predicted deficits. Each time-step’s plot now displays these values, and a separate time-series plot summarizes their evolution.

    Retaining Model and Deficit Settings:
    The function instantiate_wfm branches based on the DOWNWIND flag and the chosen MODEL (1 or 2) just as in your original code. All deficit and turbulence settings are preserved.

    Optimization:
    The evaluation function for Bayesian optimization still returns the negative RMSE, ensuring that the optimizer “maximizes” a better (lower) RMSE. Additionally, the plotting function for optimization history provides clear convergence and parameter evolution visuals.

This structure makes it easier to adjust or extend any of the individual components (for instance, changing the plotting details or adding further error statistics) without the need for a full rewrite later.

What do I think of your original approach? It’s a solid start that correctly sets up the simulation and optimization, but as you suspected, there is a benefit to modularizing. By separating concerns, you can later swap out components or add additional diagnostics (such as your proposed error metrics) with minimal changes to the overall code base.

Feel free to adjust the function boundaries or add further refinements as needed!
